{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNz1rfK3xpmR"
   },
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ySGlFOelnaHr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import  Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjQ_O1JKyH9s",
    "outputId": "df72c910-2d41-407a-a584-51349c130e3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9O49obFxttu"
   },
   "source": [
    "**Split Into Train Data & Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5BPRbgW4nn3e"
   },
   "outputs": [],
   "source": [
    "disease_types=['COVID', 'non-COVID']\n",
    "data_dir = r'D:\\FYPProject\\Dataset'\n",
    "train_dir = os.path.join(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fMQE6EEMrniq"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for defects_id, sp in enumerate(disease_types):\n",
    "    for file in os.listdir(os.path.join(train_dir, sp)):\n",
    "        train_data.append(['{}/{}'.format(sp, file), defects_id, sp])      \n",
    "train = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bOA185RhroWb"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 150\n",
    "def read_image(filepath):\n",
    "    return cv2.imread(os.path.join(data_dir, filepath)) \n",
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0aI-ZCor8lr",
    "outputId": "32f7e10d-6a56-43a9-b5a8-27962ae84e1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1824it [01:08, 26.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1824, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "for i, file in tqdm(enumerate(train['File'].values)):\n",
    "    image = read_image(file)\n",
    "    if image is not None:\n",
    "        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "X_Train = X_train / 255.\n",
    "print(X_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yvlrhwtXr9uo"
   },
   "outputs": [],
   "source": [
    "Y_train = train['DiseaseID'].values\n",
    "Y_train = to_categorical(Y_train, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aa3zZ55CsBqm"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcaWuy-DxxuJ"
   },
   "source": [
    "**Define VGG16 Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTzIgz1xsC6s",
    "outputId": "f1936fe1-79c6-4234-c1d6-728c9cc5b499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 83s 1us/step\n",
      "58900480/58889256 [==============================] - 83s 1us/step\n",
      "Model: \"VGG16_Architecture\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849,602\n",
      "Trainable params: 133,378\n",
      "Non-trainable params: 14,716,224\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohail Ahmed\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights = 'imagenet', include_top = False,input_shape=(150,150,3))\n",
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(2, activation = 'softmax')(x)\n",
    "model = Model(vgg16_model.input,predictions)\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "optimizer = Adam(lr=0.0002)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model._name = \"VGG16_Architecture\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0e-97zBx1tX"
   },
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHjD6EQSsFC_",
    "outputId": "ba69f58c-956d-4fcd-db2a-b5d60dbdf507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.5835WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68222, saving model to VGG16_Model.h5\n",
      "10/10 [==============================] - 100s 9s/step - loss: 0.8860 - accuracy: 0.5835 - val_loss: 0.6822 - val_accuracy: 0.5410\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.6922WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.7051 - accuracy: 0.6922\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 57s 5s/step - loss: 0.5229 - accuracy: 0.7844\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.7781WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.5377 - accuracy: 0.7781\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.8250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.4586 - accuracy: 0.8250\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.4886 - accuracy: 0.8188\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8331WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.4276 - accuracy: 0.8331\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8484WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.4237 - accuracy: 0.8484\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8331WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.4036 - accuracy: 0.8331\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.3590 - accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.3601 - accuracy: 0.8609\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.8672WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3705 - accuracy: 0.8672\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.3753 - accuracy: 0.8609\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.8797WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3194 - accuracy: 0.8797\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8752WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.3388 - accuracy: 0.8752\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.8979WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 57s 5s/step - loss: 0.3026 - accuracy: 0.8979\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.2874 - accuracy: 0.8969\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8703WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.3111 - accuracy: 0.8703\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8797WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3257 - accuracy: 0.8797\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 68s 6s/step - loss: 0.3147 - accuracy: 0.8969\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.8979WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.2844 - accuracy: 0.8979\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8859WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.3046 - accuracy: 0.8859\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.8906WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.2871 - accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.8930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.2812 - accuracy: 0.8930\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.8947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2960 - accuracy: 0.8947\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9203WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.2364 - accuracy: 0.9203\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.8844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.3053 - accuracy: 0.8844\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8734WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.3074 - accuracy: 0.8734\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8963WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.3021 - accuracy: 0.8963\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9028WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.2795 - accuracy: 0.9028\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9092WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 69s 6s/step - loss: 0.2589 - accuracy: 0.9092\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9078WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.2674 - accuracy: 0.9078\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8922WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.2917 - accuracy: 0.8922\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9078WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.2409 - accuracy: 0.9078\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9078WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2600 - accuracy: 0.9078\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8984WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.2726 - accuracy: 0.8984\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.8947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.2462 - accuracy: 0.8947\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9011WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.2603 - accuracy: 0.9011\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9060WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.2339 - accuracy: 0.9060\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9044WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.2596 - accuracy: 0.9044\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2213 - accuracy: 0.9156\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.2535 - accuracy: 0.9172\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.8865WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.2752 - accuracy: 0.8865\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.2202 - accuracy: 0.9172\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9328WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.1992 - accuracy: 0.9328\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9206WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.2174 - accuracy: 0.9206\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9078WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.2588 - accuracy: 0.9078\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9047WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.2389 - accuracy: 0.9047\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.2281 - accuracy: 0.9156\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.2625 - accuracy: 0.9125\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9203WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 74s 7s/step - loss: 0.2108 - accuracy: 0.9203\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9287WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.1844 - accuracy: 0.9287\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2287 - accuracy: 0.9156\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.9157WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 46s 4s/step - loss: 0.2387 - accuracy: 0.9157\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9238WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2058 - accuracy: 0.9238\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.8914WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.2547 - accuracy: 0.8914\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9297WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.1995 - accuracy: 0.9297\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.2090 - accuracy: 0.9219\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9266WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.2202 - accuracy: 0.9266\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9203WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.2343 - accuracy: 0.9203\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9297WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 46s 4s/step - loss: 0.2017 - accuracy: 0.9297\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 39s 4s/step - loss: 0.2295 - accuracy: 0.9141\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.1824 - accuracy: 0.9312\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9109WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2342 - accuracy: 0.9109\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.2192 - accuracy: 0.9125\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.9125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2247 - accuracy: 0.9125\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9011WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.2465 - accuracy: 0.9011\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.2478 - accuracy: 0.9172\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.2178 - accuracy: 0.9156\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9391WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.1677 - accuracy: 0.9391\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9281WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.2080 - accuracy: 0.9281\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9344WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.2104 - accuracy: 0.9344\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.2078 - accuracy: 0.9141\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.2296 - accuracy: 0.9141\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9222WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.2007 - accuracy: 0.9222\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9031WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.2423 - accuracy: 0.9031\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.2327 - accuracy: 0.9156\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8898WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.2581 - accuracy: 0.8898\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2283 - accuracy: 0.9219\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.1845 - accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9190WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.2183 - accuracy: 0.9190\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.2151 - accuracy: 0.9219\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2138 - accuracy: 0.9250\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9266WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 42s 4s/step - loss: 0.2007 - accuracy: 0.9266\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 42s 4s/step - loss: 0.2191 - accuracy: 0.9172\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.2296 - accuracy: 0.9219\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9328WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1888 - accuracy: 0.9328\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2285 - accuracy: 0.9172\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9266WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.1888 - accuracy: 0.9266\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9344WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2139 - accuracy: 0.9344\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.9312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.1780 - accuracy: 0.9312\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2231 - accuracy: 0.9156\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9271WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.2002 - accuracy: 0.9271\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9203WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 5s/step - loss: 0.2301 - accuracy: 0.9203\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.9016WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.2277 - accuracy: 0.9016\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9391WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 42s 4s/step - loss: 0.1875 - accuracy: 0.9391\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9156WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.2016 - accuracy: 0.9156\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9078WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.2293 - accuracy: 0.9078\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2172 - accuracy: 0.9141\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.1742 - accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(rotation_range=40, \n",
    "                        width_shift_range=0.2, \n",
    "                        height_shift_range=0.2, \n",
    "                        zoom_range=0.2, \n",
    "                        horizontal_flip=True, \n",
    "                        vertical_flip=True,\n",
    "                        shear_range=0.2) \n",
    "\n",
    "train_generator = training_datagen.flow(\n",
    "\tX_train, Y_train,\n",
    "batch_size=64\n",
    ")\n",
    "training_datagen.fit(X_train)\n",
    "\n",
    "\n",
    "filepath=\"VGG16_Model.h5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True, mode='min',verbose=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=10, epochs=100,\n",
    "                              validation_data=(X_val, Y_val),validation_steps=50,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHImwyDx40f"
   },
   "source": [
    "**Plot the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8Wgt_QeG-NQx"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "JDH2QVT-B4A7",
    "outputId": "462ef14f-0646-49f4-f470-795033258846"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SOHAIL~1\\AppData\\Local\\Temp/ipykernel_2140/4105407696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraiN & Val Acc VS Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   3020\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \"\"\"\n\u001b[0;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('TraiN & Val Acc VS Epochs')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "2yT_i3mtB4zC",
    "outputId": "9ddf3dab-4e65-406f-fa6b-b7a218049b16"
   },
   "outputs": [],
   "source": [
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('TraiN & Val Loss VS Epochs')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLDbYtkfAZoT",
    "outputId": "dc975fba-b0a5-473f-def6-5864cdbcf856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 13s 2s/step - loss: 0.6822 - accuracy: 0.5410\n",
      "Test Loss: 0.6822219491004944\n",
      "Test accuracy: 54.09836173057556\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"VGG16_Model.h5\")\n",
    "score = model.evaluate(X_val, Y_val ,verbose=1)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "53FrHSBZIwBX",
    "outputId": "1ec9c293-ffa9-43f0-d4bc-9dc1882eebc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_val)\n",
    "Y_predx = np.argmax(Y_pred, axis = -1)\n",
    "Y_valx = np.argmax(Y_val, axis = -1)\n",
    "cf_matrix = confusion_matrix(Y_valx, Y_predx)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot = labels, fmt = '')\n",
    "plt.title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtthdEBpKBb3PFe3OXUzaG",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "COVID Chest X Ray (VGG16)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
