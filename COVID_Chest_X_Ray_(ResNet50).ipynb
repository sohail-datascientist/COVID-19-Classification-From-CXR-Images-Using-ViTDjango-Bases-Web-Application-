{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNz1rfK3xpmR"
   },
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ySGlFOelnaHr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import  Flatten, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjQ_O1JKyH9s",
    "outputId": "728f020d-a665-4bd1-9fa9-94fd68953240"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.version:  2.9.0\n",
      "tf.keras.version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"tf.version: \", tf.version.VERSION)\n",
    "print(\"tf.keras.version: \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWbeeYIyqt8N"
   },
   "source": [
    "**Fetch Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9O49obFxttu"
   },
   "source": [
    "**Split Into Train Data & Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5BPRbgW4nn3e"
   },
   "outputs": [],
   "source": [
    "disease_types=['COVID', 'non-COVID']\n",
    "data_dir = r'E:\\FYPProject\\Dataset'\n",
    "train_dir = os.path.join(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fMQE6EEMrniq"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for defects_id, sp in enumerate(disease_types):\n",
    "    for file in os.listdir(os.path.join(train_dir, sp)):\n",
    "        train_data.append(['{}/{}'.format(sp, file), defects_id, sp])      \n",
    "train = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bOA185RhroWb"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "def read_image(filepath):\n",
    "    return cv2.imread(os.path.join(data_dir, filepath)) \n",
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0aI-ZCor8lr",
    "outputId": "c5bf5a26-448e-4195-b9f6-2125deef8e81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1825it [00:49, 37.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "for i, file in tqdm(enumerate(train['File'].values)):\n",
    "    image = read_image(file)\n",
    "    if image is not None:\n",
    "        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "X_Train = X_train / 255.\n",
    "print(X_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yvlrhwtXr9uo"
   },
   "outputs": [],
   "source": [
    "Y_train = train['DiseaseID'].values\n",
    "Y_train = to_categorical(Y_train, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aa3zZ55CsBqm"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcaWuy-DxxuJ"
   },
   "source": [
    "**Define VGG16 Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OLERkmn6_4-M"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "SIZE=64\n",
    "N_ch=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PTzIgz1xsC6s"
   },
   "outputs": [],
   "source": [
    "def build_resnet50():\n",
    "    resnet50 = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    input = Input(shape=(SIZE, SIZE, N_ch))\n",
    "    x = Conv2D(3, (3, 3), padding='same')(input)\n",
    "    \n",
    "    x = resnet50(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # multi output\n",
    "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
    " \n",
    "\n",
    "    # model\n",
    "    model = Model(input,output)\n",
    "    \n",
    "    optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0e-97zBx1tX"
   },
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHjD6EQSsFC_",
    "outputId": "f66e0382-7afd-44fb-958e-855356eab5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 3)         84        \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " root (Dense)                (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,122,070\n",
      "Trainable params: 24,064,342\n",
      "Non-trainable params: 57,728\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAJI\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = build_resnet50()\n",
    "annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.70, patience=5, verbose=1, min_lr=1e-4)\n",
    "checkpoint = ModelCheckpoint('ResNet50_Model.h5', verbose=1, save_best_only=True)\n",
    "datagen = ImageDataGenerator(rotation_range=360, \n",
    "                        width_shift_range=0.2, \n",
    "                        height_shift_range=0.2,\n",
    "                        zoom_range=0.2, \n",
    "                        horizontal_flip=True, \n",
    "                        vertical_flip=True) \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3WI0Ac7Apcm",
    "outputId": "401bd169-9380-4de8-d22c-71f67ffa9a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAJI\\AppData\\Local\\Temp\\ipykernel_7568\\391079107.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7221\n",
      "Epoch 1: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 155s 7s/step - loss: 0.6811 - accuracy: 0.7221 - val_loss: 0.9240 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.8138\n",
      "Epoch 2: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.4706 - accuracy: 0.8138 - val_loss: 2.6583 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8596\n",
      "Epoch 3: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.3455 - accuracy: 0.8596 - val_loss: 4.0756 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.8904\n",
      "Epoch 4: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.2827 - accuracy: 0.8904 - val_loss: 4.4452 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.9241\n",
      "Epoch 5: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 151s 7s/step - loss: 0.2466 - accuracy: 0.9241 - val_loss: 4.6139 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9319\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002100000018253922.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 150s 7s/step - loss: 0.1902 - accuracy: 0.9319 - val_loss: 5.6937 - val_accuracy: 0.5041 - lr: 0.0030\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9262\n",
      "Epoch 7: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 150s 7s/step - loss: 0.1785 - accuracy: 0.9262 - val_loss: 4.6058 - val_accuracy: 0.5041 - lr: 0.0021\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9446\n",
      "Epoch 8: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 151s 7s/step - loss: 0.1493 - accuracy: 0.9446 - val_loss: 6.5616 - val_accuracy: 0.5041 - lr: 0.0021\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9413\n",
      "Epoch 9: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 150s 7s/step - loss: 0.1718 - accuracy: 0.9413 - val_loss: 9.2530 - val_accuracy: 0.5041 - lr: 0.0021\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9542\n",
      "Epoch 10: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 150s 7s/step - loss: 0.1244 - accuracy: 0.9542 - val_loss: 10.4762 - val_accuracy: 0.5041 - lr: 0.0021\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9556\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0014699999475851653.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.1270 - accuracy: 0.9556 - val_loss: 12.1976 - val_accuracy: 0.5041 - lr: 0.0021\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9527\n",
      "Epoch 12: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.1374 - accuracy: 0.9527 - val_loss: 11.6189 - val_accuracy: 0.5041 - lr: 0.0015\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9470\n",
      "Epoch 13: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.1360 - accuracy: 0.9470 - val_loss: 10.8476 - val_accuracy: 0.5041 - lr: 0.0015\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9534\n",
      "Epoch 14: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 161s 7s/step - loss: 0.1217 - accuracy: 0.9534 - val_loss: 10.4513 - val_accuracy: 0.5041 - lr: 0.0015\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9692\n",
      "Epoch 15: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.0844 - accuracy: 0.9692 - val_loss: 9.3175 - val_accuracy: 0.5041 - lr: 0.0015\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9635\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0010289999307133257.\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 161s 7s/step - loss: 0.0817 - accuracy: 0.9635 - val_loss: 7.5743 - val_accuracy: 0.5041 - lr: 0.0015\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9678\n",
      "Epoch 17: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 32563s 1550s/step - loss: 0.0914 - accuracy: 0.9678 - val_loss: 6.8001 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9706\n",
      "Epoch 18: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 175s 8s/step - loss: 0.0781 - accuracy: 0.9706 - val_loss: 6.2231 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9778\n",
      "Epoch 19: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 6.0082 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9821\n",
      "Epoch 20: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 5.1976 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9771\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0007202999433502554.\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 152s 7s/step - loss: 0.0642 - accuracy: 0.9771 - val_loss: 4.7532 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9713\n",
      "Epoch 22: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 150s 7s/step - loss: 0.0928 - accuracy: 0.9713 - val_loss: 4.4278 - val_accuracy: 0.5041 - lr: 7.2030e-04\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9857\n",
      "Epoch 23: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 153s 7s/step - loss: 0.0558 - accuracy: 0.9857 - val_loss: 3.9541 - val_accuracy: 0.5041 - lr: 7.2030e-04\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9785\n",
      "Epoch 24: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 163s 7s/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: 3.1515 - val_accuracy: 0.5068 - lr: 7.2030e-04\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9735\n",
      "Epoch 25: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.0741 - accuracy: 0.9735 - val_loss: 2.2692 - val_accuracy: 0.5315 - lr: 7.2030e-04\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9842\n",
      "Epoch 26: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.0566 - accuracy: 0.9842 - val_loss: 1.6034 - val_accuracy: 0.5534 - lr: 7.2030e-04\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9807\n",
      "Epoch 27: val_loss did not improve from 0.77100\n",
      "22/22 [==============================] - 162s 7s/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 1.1245 - val_accuracy: 0.6219 - lr: 7.2030e-04\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9785\n",
      "Epoch 28: val_loss improved from 0.77100 to 0.70908, saving model to ResNet50_Model.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to create file (unable to open file: name = 'ResNet50_Model.h5', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mannealer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \n\u001b[0;32m   2251\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2259\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py:507\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[0;32m    502\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    503\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    504\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    505\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    506\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 507\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mcreate(name, h5f\u001b[38;5;241m.\u001b[39mACC_EXCL, fapl\u001b[38;5;241m=\u001b[39mfapl, fcpl\u001b[38;5;241m=\u001b[39mfcpl)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:126\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to create file (unable to open file: name = 'ResNet50_Model.h5', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
    "               steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "               epochs=EPOCHS,\n",
    "               verbose=1,\n",
    "               callbacks=[annealer, checkpoint],\n",
    "               validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHImwyDx40f"
   },
   "source": [
    "**Plot the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Wgt_QeG-NQx"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "JDH2QVT-B4A7",
    "outputId": "239be626-accf-4698-c028-7c6069027c4d"
   },
   "outputs": [],
   "source": [
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('TraiN & Val Acc VS Epochs')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "2yT_i3mtB4zC",
    "outputId": "b4af66f6-8c33-4f0c-dc7e-807501903ce6"
   },
   "outputs": [],
   "source": [
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('TraiN & Val Loss VS Epochs')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLDbYtkfAZoT",
    "outputId": "24d33ad3-d5fd-467e-a3d3-2a85da9496da"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"ResNet50_Model.h5\")\n",
    "score = model.evaluate(X_val, Y_val ,verbose=1)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "53FrHSBZIwBX",
    "outputId": "7fabab3b-2493-4105-c2b3-65aeee160ae6"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val)\n",
    "Y_predx = np.argmax(Y_pred, axis = -1)\n",
    "Y_valx = np.argmax(Y_val, axis = -1)\n",
    "cf_matrix = confusion_matrix(Y_valx, Y_predx)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot = labels, fmt = '')\n",
    "plt.title(\"Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOSoLaddd6nsR2V8j/rMiC2",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "COVID Chest X Ray (ResNet50)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
